{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0v4G/dSR2Vd8KSdKmB4gs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenust/leaf_damage_neuronet/blob/main/UnetPlusPlus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка модели:"
      ],
      "metadata": {
        "id": "Cks_WVF3KCO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p6I5pq1J4mf"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "model = smp.UnetPlusPlus(encoder_name=\"efficientnet-b0\", classes = 1, activation = \"sigmoid\")\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/нейросеть/leaves/SMP_dataset2_UnetPlusPlus_FocalLoss.pth\"))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "def load_image(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return transforms.Compose([ transforms.ToTensor(), transforms.Resize((224, 224))])(img)\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder1):\n",
        "        self.folder1 = folder1\n",
        "        self.filenames = [f for f in os.listdir(folder1)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        img1_path = os.path.join(self.folder1, filename)\n",
        "        img1 = load_image(img1_path)\n",
        "        return img1\n",
        "\n",
        "true_test = CustomDataset('/content/drive/MyDrive/нейросеть/leaves/true_test') #указать папку с исходными изображениями\n",
        "\n",
        "\n",
        "def show_valset_pred(model, cols=16):\n",
        "    images, pred_masks = [], []\n",
        "    for batch in true_test:\n",
        "        with torch.no_grad():\n",
        "            img = batch\n",
        "            images.append(binarize_image(img, 0.6))\n",
        "            output = model(img.unsqueeze(0).to(device))\n",
        "            pred_masks.append(output.cpu())\n",
        "    show(torch.stack(images)[:cols, ...])\n",
        "    show(torch.stack(pred_masks).squeeze(1)[:cols, ...])\n",
        "    show(torch.stack(pred_masks).squeeze(1)[:cols, ...] - torch.stack(images)[:cols, ...])\n",
        "\n",
        "show_valset_pred(model)"
      ],
      "metadata": {
        "id": "lyXaZSldKAmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычисление площади:"
      ],
      "metadata": {
        "id": "UZ8KhxxfMTmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "folder = '/content/drive/MyDrive/нейросеть/leaves/true_test' #указать папку с исходными изображениями\n",
        "image_sizes = []\n",
        "\n",
        "for filename in os.listdir(folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        filepath = os.path.join(folder, filename)\n",
        "        with Image.open(filepath) as img:\n",
        "            image_sizes.append(img.size)\n",
        "\n",
        "image_sizes = [(y, x) for x, y in image_sizes]\n",
        "\n",
        "def resize_images(images, sizes):\n",
        "    resized_images = []\n",
        "    for img, size in zip(images, sizes):\n",
        "        resized_img = torch.nn.functional.interpolate(img, size=size, mode='bilinear', align_corners=False)\n",
        "        resized_images.append(resized_img)\n",
        "    return resized_images\n",
        "\n",
        "images, pred_masks = [], []\n",
        "for batch in true_test:\n",
        "    with torch.no_grad():\n",
        "        img = batch\n",
        "        images.append(binarize_image(img, 0.6).unsqueeze(0))\n",
        "        output = model(img.unsqueeze(0).to(device))\n",
        "        pred_masks.append(output.cpu())\n",
        "\n",
        "resized_images = resize_images(images, image_sizes)\n",
        "resized_masks = resize_images(pred_masks, image_sizes)\n",
        "\n",
        "def subtract_tensor_lists(list1, list2):\n",
        "    result = []\n",
        "    for t1, t2 in zip(list1, list2):\n",
        "        subtracted_tensor = binarize_image(t1 - t2, 0.05)\n",
        "        result.append(subtracted_tensor.squeeze())\n",
        "    return result\n",
        "\n",
        "# Выполняем операцию вычитания одного списка из другого\n",
        "subtracted_list = subtract_tensor_lists(resized_masks, resized_images)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(subtracted_list[5], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KGud0UTSMTQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def count_black_pixels(image_tensor):\n",
        "    # Преобразуем тензор в массив NumPy\n",
        "    image_array = np.array(image_tensor)\n",
        "\n",
        "    # Подсчитываем количество черных пикселей\n",
        "    num_black_pixels = np.sum(image_array == 0)\n",
        "\n",
        "    return num_black_pixels\n",
        "\n",
        "square  = []\n",
        "for tensor in subtracted_list:\n",
        "  square.append(count_black_pixels(tensor))\n",
        "\n",
        "print(square)"
      ],
      "metadata": {
        "id": "5CwW66CONFDe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}